{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4c467f4",
   "metadata": {},
   "source": [
    "# Deep Deterministic Policy Gradients Paper Implement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdbc99a",
   "metadata": {},
   "source": [
    "* need reply buffer class\n",
    "* need a for a target Q-net f(s,a)\n",
    "* will use batch norm\n",
    "* policy is deterministic, exploit vs explore\n",
    "* (deterministic ploicy means outputs actual actions isntead of probablity)\n",
    "* will need a way to bound the actions to the env limits\n",
    "* 2 actors, 2 critic nets, a target for each\n",
    "* updates are soft, according to theta_prime = tau*theta + (1-tau)*theta_prime, tau << 1\n",
    "* target actor is just evaluation actor + some noise\n",
    "* they used Ornstien Uhlnbeck. --> will need class for noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aaaec74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Activation, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7017efa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_learning_curve(x, scores, figure_file):\n",
    "    running_avg = np.zeros(len(scores))\n",
    "    for i in range(len(running_avg)):\n",
    "        running_avg[i] = np.mean(scores[max(0, i-100):(i+1)])\n",
    "    plt.plot(x, running_avg)\n",
    "    plt.title('Running average of previous 100 scores')\n",
    "    plt.savefig(figure_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39bd1c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OUActionNoise(object):\n",
    "    def __init__(self, mu, sigma=0.15, theta=.2, dt=1e-2, x0=None):\n",
    "        self.theta = theta\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        self.dt = dt\n",
    "        self.x0 = x0\n",
    "        self.reset()\n",
    "\n",
    "    def __call__(self):\n",
    "        x = self.x_prev + self.theta * (self.mu - self.x_prev) * self.dt + \\\n",
    "            self.sigma * np.sqrt(self.dt) * np.random.normal(size=self.mu.shape)\n",
    "        self.x_prev = x\n",
    "        return x\n",
    "\n",
    "    def reset(self):\n",
    "        self.x_prev = self.x0 if self.x0 is not None else np.zeros_like(self.mu)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'OrnsteinUhlenbeckActionNoise(mu={}, sigma={})'.format(\n",
    "                                                            self.mu, self.sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3c25b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, max_size, input_shape, n_actions):\n",
    "        self.mem_size = max_size\n",
    "        self.mem_cntr = 0\n",
    "        self.state_memory = np.zeros((self.mem_size, *input_shape))\n",
    "        self.new_state_memory = np.zeros((self.mem_size, *input_shape))\n",
    "        self.action_memory = np.zeros((self.mem_size, n_actions))\n",
    "        self.reward_memory = np.zeros(self.mem_size)\n",
    "        self.terminal_memory = np.zeros(self.mem_size, dtype=np.bool)\n",
    "\n",
    "    def store_transition(self, state, action, reward, state_, done):\n",
    "        index = self.mem_cntr % self.mem_size\n",
    "\n",
    "        self.state_memory[index] = state\n",
    "        self.new_state_memory[index] = state_\n",
    "        self.action_memory[index] = action\n",
    "        self.reward_memory[index] = reward\n",
    "        self.terminal_memory[index] = done\n",
    "\n",
    "        self.mem_cntr += 1\n",
    "\n",
    "    def sample_buffer(self, batch_size):\n",
    "        max_mem = min(self.mem_cntr, self.mem_size)\n",
    "\n",
    "        batch = np.random.choice(max_mem, batch_size, replace=False)\n",
    "\n",
    "        states = self.state_memory[batch]\n",
    "        states_ = self.new_state_memory[batch]\n",
    "        actions = self.action_memory[batch]\n",
    "        rewards = self.reward_memory[batch]\n",
    "        dones = self.terminal_memory[batch]\n",
    "\n",
    "        return states, actions, rewards, states_, dones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6a1a368",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CriticNetwork(keras.Model):\n",
    "    def __init__(self, fc1_dims=512, fc2_dims=512,\n",
    "            name='critic', chkpt_dir='tmp/ddpg'):\n",
    "        super(CriticNetwork, self).__init__()\n",
    "        self.fc1_dims = fc1_dims\n",
    "        self.fc2_dims = fc2_dims\n",
    "\n",
    "        self.model_name = name\n",
    "        self.checkpoint_dir = chkpt_dir\n",
    "        self.checkpoint_file = os.path.join(self.checkpoint_dir, \n",
    "                    self.model_name+'_ddpg.h5')\n",
    "\n",
    "        self.fc1 = Dense(self.fc1_dims, activation='relu')\n",
    "        self.fc2 = Dense(self.fc2_dims, activation='relu')\n",
    "        self.q = Dense(1, activation=None)\n",
    "\n",
    "    def call(self, state, action):\n",
    "        action_value = self.fc1(tf.concat([state, action], axis=1))\n",
    "        action_value = self.fc2(action_value)\n",
    "\n",
    "        q = self.q(action_value)\n",
    "\n",
    "        return q\n",
    "\n",
    "class ActorNetwork(keras.Model):\n",
    "    def __init__(self, fc1_dims=512, fc2_dims=512, n_actions=2, name='actor',\n",
    "            chkpt_dir='tmp/ddpg'):\n",
    "        super(ActorNetwork, self).__init__()\n",
    "        self.fc1_dims = fc1_dims\n",
    "        self.fc2_dims = fc2_dims\n",
    "        self.n_actions = n_actions\n",
    "\n",
    "        self.model_name = name\n",
    "        self.checkpoint_dir = chkpt_dir\n",
    "        self.checkpoint_file = os.path.join(self.checkpoint_dir, \n",
    "                    self.model_name+'_ddpg.h5')\n",
    "\n",
    "        self.fc1 = Dense(self.fc1_dims, activation='relu')\n",
    "        self.fc2 = Dense(self.fc2_dims, activation='relu')\n",
    "        self.mu = Dense(self.n_actions, activation='tanh')\n",
    "\n",
    "    def call(self, state):\n",
    "        prob = self.fc1(state)\n",
    "        prob = self.fc2(prob)\n",
    "\n",
    "        mu = self.mu(prob)\n",
    "\n",
    "        return mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a19757a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, input_dims, alpha=0.001, beta=0.002, env=None,\n",
    "                 gamma=0.99, n_actions=2, max_size=1000000, tau=0.005,\n",
    "                 fc1=400, fc2=300, batch_size=64, noise=0.1):\n",
    "        self.gamma = gamma\n",
    "        self.tau = tau\n",
    "        self.memory = ReplayBuffer(max_size, input_dims, n_actions)\n",
    "        self.batch_size = batch_size\n",
    "        self.n_actions = n_actions\n",
    "        self.noise = noise\n",
    "        self.max_action = env.action_space.high[0]\n",
    "        self.min_action = env.action_space.low[0]\n",
    "\n",
    "        self.actor = ActorNetwork(n_actions=n_actions, name='actor')\n",
    "        self.critic = CriticNetwork(name='critic')\n",
    "        self.target_actor = ActorNetwork(n_actions=n_actions,\n",
    "                                         name='target_actor')\n",
    "        self.target_critic = CriticNetwork(name='target_critic')\n",
    "\n",
    "        self.actor.compile(optimizer=Adam(learning_rate=alpha))\n",
    "        self.critic.compile(optimizer=Adam(learning_rate=beta))\n",
    "        self.target_actor.compile(optimizer=Adam(learning_rate=alpha))\n",
    "        self.target_critic.compile(optimizer=Adam(learning_rate=beta))\n",
    "\n",
    "        self.update_network_parameters(tau=1)\n",
    "\n",
    "    def update_network_parameters(self, tau=None):\n",
    "        if tau is None:\n",
    "            tau = self.tau\n",
    "\n",
    "        weights = []\n",
    "        targets = self.target_actor.weights\n",
    "        for i, weight in enumerate(self.actor.weights):\n",
    "            weights.append(weight * tau + targets[i]*(1-tau))\n",
    "        self.target_actor.set_weights(weights)\n",
    "\n",
    "        weights = []\n",
    "        targets = self.target_critic.weights\n",
    "        for i, weight in enumerate(self.critic.weights):\n",
    "            weights.append(weight * tau + targets[i]*(1-tau))\n",
    "        self.target_critic.set_weights(weights)\n",
    "\n",
    "    def remember(self, state, action, reward, new_state, done):\n",
    "        self.memory.store_transition(state, action, reward, new_state, done)\n",
    "\n",
    "    def save_models(self):\n",
    "        print('... saving models ...')\n",
    "        self.actor.save_weights(self.actor.checkpoint_file)\n",
    "        self.target_actor.save_weights(self.target_actor.checkpoint_file)\n",
    "        self.critic.save_weights(self.critic.checkpoint_file)\n",
    "        self.target_critic.save_weights(self.target_critic.checkpoint_file)\n",
    "\n",
    "    def load_models(self):\n",
    "        print('... loading models ...')\n",
    "        self.actor.load_weights(self.actor.checkpoint_file)\n",
    "        self.target_actor.load_weights(self.target_actor.checkpoint_file)\n",
    "        self.critic.load_weights(self.critic.checkpoint_file)\n",
    "        self.target_critic.load_weights(self.target_critic.checkpoint_file)\n",
    "\n",
    "    def choose_action(self, observation, evaluate=False):\n",
    "        state = tf.convert_to_tensor([observation], dtype=tf.float32)\n",
    "        actions = self.actor(state)\n",
    "        if not evaluate:\n",
    "            actions += tf.random.normal(shape=[self.n_actions],\n",
    "                                        mean=0.0, stddev=self.noise)\n",
    "        # note that if the env has an action > 1, we have to multiply by\n",
    "        # max action at some point\n",
    "        actions = tf.clip_by_value(actions, self.min_action, self.max_action)\n",
    "\n",
    "        return actions[0]\n",
    "\n",
    "    def learn(self):\n",
    "        if self.memory.mem_cntr < self.batch_size:\n",
    "            return\n",
    "\n",
    "        state, action, reward, new_state, done = \\\n",
    "            self.memory.sample_buffer(self.batch_size)\n",
    "\n",
    "        states = tf.convert_to_tensor(state, dtype=tf.float32)\n",
    "        states_ = tf.convert_to_tensor(new_state, dtype=tf.float32)\n",
    "        rewards = tf.convert_to_tensor(reward, dtype=tf.float32)\n",
    "        actions = tf.convert_to_tensor(action, dtype=tf.float32)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            target_actions = self.target_actor(states_)\n",
    "            critic_value_ = tf.squeeze(self.target_critic(\n",
    "                                states_, target_actions), 1)\n",
    "            critic_value = tf.squeeze(self.critic(states, actions), 1)\n",
    "            target = rewards + self.gamma*critic_value_*(1-done)\n",
    "            critic_loss = keras.losses.MSE(target, critic_value)\n",
    "\n",
    "        critic_network_gradient = tape.gradient(critic_loss,\n",
    "                                                self.critic.trainable_variables)\n",
    "        self.critic.optimizer.apply_gradients(zip(\n",
    "            critic_network_gradient, self.critic.trainable_variables))\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            new_policy_actions = self.actor(states)\n",
    "            actor_loss = -self.critic(states, new_policy_actions)\n",
    "            actor_loss = tf.math.reduce_mean(actor_loss)\n",
    "\n",
    "        actor_network_gradient = tape.gradient(actor_loss,\n",
    "                                               self.actor.trainable_variables)\n",
    "        self.actor.optimizer.apply_gradients(zip(\n",
    "            actor_network_gradient, self.actor.trainable_variables))\n",
    "\n",
    "        self.update_network_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5c7158",
   "metadata": {},
   "source": [
    "# Testing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dbf187f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14797962",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-e6fe9f0a0db2>:9: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  self.terminal_memory = np.zeros(self.mem_size, dtype=np.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... saving models ...\n",
      "episode  0 score -1178.9 avg score -1178.9\n",
      "episode  1 score -1673.1 avg score -1426.0\n",
      "episode  2 score -1582.1 avg score -1478.0\n",
      "episode  3 score -1635.2 avg score -1517.3\n",
      "episode  4 score -1813.9 avg score -1576.6\n",
      "episode  5 score -906.1 avg score -1464.9\n",
      "episode  6 score -1458.2 avg score -1463.9\n",
      "episode  7 score -1638.1 avg score -1485.7\n",
      "episode  8 score -1837.4 avg score -1524.8\n",
      "episode  9 score -1663.1 avg score -1538.6\n",
      "episode  10 score -1572.1 avg score -1541.7\n",
      "episode  11 score -1838.2 avg score -1566.4\n",
      "episode  12 score -1748.3 avg score -1580.4\n",
      "episode  13 score -1105.3 avg score -1546.4\n",
      "episode  14 score -1366.7 avg score -1534.4\n",
      "episode  15 score -999.6 avg score -1501.0\n",
      "episode  16 score -866.0 avg score -1463.7\n",
      "episode  17 score -985.3 avg score -1437.1\n",
      "episode  18 score -743.4 avg score -1400.6\n",
      "episode  19 score -1846.7 avg score -1422.9\n",
      "episode  20 score -1484.7 avg score -1425.8\n",
      "episode  21 score -1029.4 avg score -1407.8\n",
      "episode  22 score -1133.2 avg score -1395.9\n",
      "episode  23 score -126.9 avg score -1343.0\n",
      "episode  24 score -1032.2 avg score -1330.6\n",
      "episode  25 score -996.9 avg score -1317.7\n",
      "episode  26 score -990.7 avg score -1305.6\n",
      "episode  27 score -1175.3 avg score -1301.0\n",
      "episode  28 score -1320.2 avg score -1301.6\n",
      "episode  29 score -127.3 avg score -1262.5\n",
      "episode  30 score -245.0 avg score -1229.7\n",
      "episode  31 score -371.3 avg score -1202.8\n",
      "episode  32 score -740.4 avg score -1188.8\n",
      "episode  33 score -1163.9 avg score -1188.1\n",
      "... saving models ...\n",
      "episode  34 score -508.0 avg score -1168.7\n",
      "... saving models ...\n",
      "episode  35 score -934.8 avg score -1162.2\n",
      "... saving models ...\n",
      "episode  36 score -123.2 avg score -1134.1\n",
      "... saving models ...\n",
      "episode  37 score -244.7 avg score -1110.7\n",
      "... saving models ...\n",
      "episode  38 score -125.6 avg score -1085.4\n",
      "episode  39 score -1815.5 avg score -1103.7\n",
      "episode  40 score -1869.4 avg score -1122.3\n",
      "episode  41 score -243.1 avg score -1101.4\n",
      "... saving models ...\n",
      "episode  42 score -123.3 avg score -1078.7\n",
      "episode  43 score -1823.6 avg score -1095.6\n",
      "... saving models ...\n",
      "episode  44 score -119.2 avg score -1073.9\n",
      "... saving models ...\n",
      "episode  45 score -0.4 avg score -1050.6\n",
      "... saving models ...\n",
      "episode  46 score -251.8 avg score -1033.6\n",
      "... saving models ...\n",
      "episode  47 score -120.8 avg score -1014.6\n",
      "... saving models ...\n",
      "episode  48 score -125.6 avg score -996.4\n",
      "... saving models ...\n",
      "episode  49 score -120.7 avg score -978.9\n",
      "... saving models ...\n",
      "episode  50 score -236.2 avg score -964.3\n",
      "... saving models ...\n",
      "episode  51 score -125.9 avg score -948.2\n",
      "... saving models ...\n",
      "episode  52 score -240.6 avg score -934.9\n",
      "... saving models ...\n",
      "episode  53 score -242.5 avg score -922.0\n",
      "... saving models ...\n",
      "episode  54 score -122.2 avg score -907.5\n",
      "... saving models ...\n",
      "episode  55 score -123.1 avg score -893.5\n",
      "... saving models ...\n",
      "episode  56 score -120.6 avg score -879.9\n",
      "... saving models ...\n",
      "episode  57 score -780.6 avg score -878.2\n",
      "... saving models ...\n",
      "episode  58 score -359.0 avg score -869.4\n",
      "... saving models ...\n",
      "episode  59 score -124.9 avg score -857.0\n",
      "... saving models ...\n",
      "episode  60 score -126.6 avg score -845.0\n",
      "... saving models ...\n",
      "episode  61 score -363.6 avg score -837.3\n",
      "... saving models ...\n",
      "episode  62 score -122.7 avg score -825.9\n",
      "... saving models ...\n",
      "episode  63 score -362.8 avg score -818.7\n",
      "... saving models ...\n",
      "episode  64 score -494.5 avg score -813.7\n",
      "... saving models ...\n",
      "episode  65 score -362.6 avg score -806.9\n",
      "... saving models ...\n",
      "episode  66 score -120.1 avg score -796.6\n",
      "... saving models ...\n",
      "episode  67 score -369.0 avg score -790.3\n",
      "... saving models ...\n",
      "episode  68 score -523.4 avg score -786.5\n",
      "... saving models ...\n",
      "episode  69 score -351.9 avg score -780.3\n",
      "... saving models ...\n",
      "episode  70 score -121.5 avg score -771.0\n",
      "... saving models ...\n",
      "episode  71 score -124.0 avg score -762.0\n",
      "... saving models ...\n",
      "episode  72 score -240.9 avg score -754.8\n",
      "... saving models ...\n",
      "episode  73 score -358.6 avg score -749.5\n",
      "... saving models ...\n",
      "episode  74 score -240.8 avg score -742.7\n",
      "... saving models ...\n",
      "episode  75 score -122.4 avg score -734.6\n",
      "... saving models ...\n",
      "episode  76 score -123.0 avg score -726.6\n",
      "... saving models ...\n",
      "episode  77 score -474.4 avg score -723.4\n",
      "... saving models ...\n",
      "episode  78 score -124.4 avg score -715.8\n",
      "episode  79 score -1803.2 avg score -729.4\n",
      "episode  80 score -368.3 avg score -724.9\n",
      "episode  81 score -495.6 avg score -722.1\n",
      "... saving models ...\n",
      "episode  82 score -0.5 avg score -713.4\n",
      "... saving models ...\n",
      "episode  83 score -360.2 avg score -709.2\n",
      "... saving models ...\n",
      "episode  84 score -482.3 avg score -706.6\n",
      "... saving models ...\n",
      "episode  85 score -122.7 avg score -699.8\n",
      "... saving models ...\n",
      "episode  86 score -0.2 avg score -691.7\n",
      "... saving models ...\n",
      "episode  87 score -491.2 avg score -689.5\n",
      "... saving models ...\n",
      "episode  88 score -119.4 avg score -683.0\n",
      "... saving models ...\n",
      "episode  89 score -124.9 avg score -676.8\n",
      "... saving models ...\n",
      "episode  90 score -353.8 avg score -673.3\n",
      "... saving models ...\n",
      "episode  91 score -0.4 avg score -666.0\n",
      "... saving models ...\n",
      "episode  92 score -124.8 avg score -660.2\n",
      "... saving models ...\n",
      "episode  93 score -357.7 avg score -656.9\n",
      "... saving models ...\n",
      "episode  94 score -125.0 avg score -651.3\n",
      "... saving models ...\n",
      "episode  95 score -123.3 avg score -645.8\n",
      "... saving models ...\n",
      "episode  96 score -233.9 avg score -641.6\n",
      "... saving models ...\n",
      "episode  97 score -636.2 avg score -641.5\n",
      "... saving models ...\n",
      "episode  98 score -122.8 avg score -636.3\n",
      "... saving models ...\n",
      "episode  99 score -352.4 avg score -633.5\n",
      "... saving models ...\n",
      "episode  100 score -125.0 avg score -622.9\n",
      "... saving models ...\n",
      "episode  101 score -121.8 avg score -607.4\n",
      "... saving models ...\n",
      "episode  102 score -125.5 avg score -592.8\n",
      "... saving models ...\n",
      "episode  103 score -503.3 avg score -581.5\n",
      "... saving models ...\n",
      "episode  104 score -119.9 avg score -564.6\n",
      "... saving models ...\n",
      "episode  105 score -123.1 avg score -556.8\n",
      "... saving models ...\n",
      "episode  106 score -121.7 avg score -543.4\n",
      "... saving models ...\n",
      "episode  107 score -359.5 avg score -530.6\n",
      "... saving models ...\n",
      "episode  108 score -124.7 avg score -513.5\n",
      "... saving models ...\n",
      "episode  109 score -121.1 avg score -498.1\n",
      "... saving models ...\n",
      "episode  110 score -123.9 avg score -483.6\n",
      "... saving models ...\n",
      "episode  111 score -239.0 avg score -467.6\n",
      "... saving models ...\n",
      "episode  112 score -587.5 avg score -456.0\n",
      "... saving models ...\n",
      "episode  113 score -357.3 avg score -448.5\n",
      "... saving models ...\n",
      "episode  114 score -121.1 avg score -436.0\n",
      "... saving models ...\n",
      "episode  115 score -351.6 avg score -429.6\n",
      "... saving models ...\n",
      "episode  116 score -0.5 avg score -420.9\n",
      "... saving models ...\n",
      "episode  117 score -238.0 avg score -413.4\n",
      "... saving models ...\n",
      "episode  118 score -0.9 avg score -406.0\n",
      "... saving models ...\n",
      "episode  119 score -503.8 avg score -392.6\n",
      "... saving models ...\n",
      "episode  120 score -121.0 avg score -378.9\n",
      "... saving models ...\n",
      "episode  121 score -120.9 avg score -369.9\n",
      "... saving models ...\n",
      "episode  122 score -121.3 avg score -359.7\n",
      "... saving models ...\n",
      "episode  123 score -124.7 avg score -359.7\n",
      "... saving models ...\n",
      "episode  124 score -124.1 avg score -350.6\n",
      "... saving models ...\n",
      "episode  125 score -367.7 avg score -344.3\n",
      "... saving models ...\n",
      "episode  126 score -506.4 avg score -339.5\n",
      "... saving models ...\n",
      "episode  127 score -1.0 avg score -327.8\n",
      "... saving models ...\n",
      "episode  128 score -357.8 avg score -318.1\n",
      "... saving models ...\n",
      "episode  129 score -0.7 avg score -316.9\n",
      "episode  130 score -486.2 avg score -319.3\n",
      "... saving models ...\n",
      "episode  131 score -121.0 avg score -316.8\n",
      "... saving models ...\n",
      "episode  132 score -124.7 avg score -310.6\n",
      "... saving models ...\n",
      "episode  133 score -0.3 avg score -299.0\n",
      "... saving models ...\n",
      "episode  134 score -354.6 avg score -297.4\n",
      "... saving models ...\n",
      "episode  135 score -120.7 avg score -289.3\n",
      "episode  136 score -513.1 avg score -293.2\n",
      "episode  137 score -614.9 avg score -296.9\n",
      "episode  138 score -122.7 avg score -296.9\n",
      "... saving models ...\n",
      "episode  139 score -124.4 avg score -280.0\n",
      "... saving models ...\n",
      "episode  140 score -122.0 avg score -262.5\n",
      "episode  141 score -245.8 avg score -262.5\n",
      "episode  142 score -243.4 avg score -263.7\n",
      "... saving models ...\n",
      "episode  143 score -120.6 avg score -246.7\n",
      "episode  144 score -238.5 avg score -247.9\n",
      "episode  145 score -592.2 avg score -253.8\n",
      "episode  146 score -125.5 avg score -252.5\n",
      "episode  147 score -489.8 avg score -256.2\n",
      "episode  148 score -118.3 avg score -256.2\n",
      "episode  149 score -516.3 avg score -260.1\n",
      "episode  150 score -353.6 avg score -261.3\n",
      "episode  151 score -625.6 avg score -266.3\n",
      "episode  152 score -125.5 avg score -265.1\n",
      "episode  153 score -245.3 avg score -265.2\n",
      "episode  154 score -122.5 avg score -265.2\n",
      "episode  155 score -241.3 avg score -266.3\n",
      "episode  156 score -124.4 avg score -266.4\n",
      "episode  157 score -476.2 avg score -263.3\n",
      "episode  158 score -237.0 avg score -262.1\n",
      "episode  159 score -240.2 avg score -263.3\n",
      "episode  160 score -0.4 avg score -262.0\n",
      "episode  161 score -0.1 avg score -258.4\n",
      "episode  162 score -371.3 avg score -260.9\n",
      "episode  163 score -125.7 avg score -258.5\n",
      "episode  164 score -123.8 avg score -254.8\n",
      "episode  165 score -239.5 avg score -253.6\n",
      "episode  166 score -484.5 avg score -257.2\n",
      "episode  167 score -119.0 avg score -254.7\n",
      "episode  168 score -122.2 avg score -250.7\n",
      "episode  169 score -245.1 avg score -249.6\n",
      "episode  170 score -117.6 avg score -249.6\n",
      "episode  171 score -242.5 avg score -250.8\n",
      "episode  172 score -590.1 avg score -254.3\n",
      "episode  173 score -357.3 avg score -254.2\n",
      "episode  174 score -237.8 avg score -254.2\n",
      "episode  175 score -235.3 avg score -255.3\n",
      "episode  176 score -123.4 avg score -255.3\n",
      "episode  177 score -241.4 avg score -253.0\n",
      "episode  178 score -121.6 avg score -253.0\n",
      "... saving models ...\n",
      "episode  179 score -119.1 avg score -236.1\n",
      "episode  180 score -574.6 avg score -238.2\n",
      "episode  181 score -483.9 avg score -238.1\n",
      "episode  182 score -120.9 avg score -239.3\n",
      "episode  183 score -606.9 avg score -241.8\n",
      "episode  184 score -121.4 avg score -238.2\n",
      "episode  185 score -613.7 avg score -243.1\n",
      "episode  186 score -239.2 avg score -245.5\n",
      "episode  187 score -126.9 avg score -241.8\n",
      "episode  188 score -0.5 avg score -240.6\n",
      "episode  189 score -122.6 avg score -240.6\n",
      "episode  190 score -484.9 avg score -241.9\n",
      "episode  191 score -118.9 avg score -243.1\n",
      "episode  192 score -125.7 avg score -243.1\n",
      "episode  193 score -242.5 avg score -242.0\n",
      "episode  194 score -363.0 avg score -244.3\n",
      "episode  195 score -122.6 avg score -244.3\n",
      "episode  196 score -235.7 avg score -244.3\n",
      "episode  197 score -516.0 avg score -243.1\n",
      "episode  198 score -0.3 avg score -241.9\n",
      "episode  199 score -237.3 avg score -240.8\n",
      "episode  200 score -120.5 avg score -240.7\n",
      "episode  201 score -120.4 avg score -240.7\n",
      "episode  202 score -121.7 avg score -240.7\n",
      "episode  203 score -501.8 avg score -240.7\n",
      "episode  204 score -367.2 avg score -243.1\n",
      "episode  205 score -124.5 avg score -243.1\n",
      "episode  206 score -120.9 avg score -243.1\n",
      "episode  207 score -240.7 avg score -241.9\n",
      "episode  208 score -244.8 avg score -243.1\n",
      "episode  209 score -372.8 avg score -245.7\n",
      "episode  210 score -122.8 avg score -245.7\n",
      "episode  211 score -120.5 avg score -244.5\n",
      "episode  212 score -614.6 avg score -244.7\n",
      "episode  213 score -119.9 avg score -242.4\n",
      "episode  214 score -239.9 avg score -243.6\n",
      "episode  215 score -241.8 avg score -242.5\n",
      "episode  216 score -352.8 avg score -246.0\n",
      "episode  217 score -244.7 avg score -246.0\n",
      "episode  218 score -351.6 avg score -249.5\n",
      "episode  219 score -481.9 avg score -249.3\n",
      "episode  220 score -0.6 avg score -248.1\n",
      "episode  221 score -583.5 avg score -252.8\n",
      "episode  222 score -232.6 avg score -253.9\n",
      "episode  223 score -125.1 avg score -253.9\n",
      "episode  224 score -0.8 avg score -252.6\n",
      "episode  225 score -597.9 avg score -254.9\n",
      "episode  226 score -575.9 avg score -255.6\n",
      "episode  227 score -119.9 avg score -256.8\n",
      "episode  228 score -125.4 avg score -254.5\n",
      "episode  229 score -236.6 avg score -256.9\n",
      "episode  230 score -361.8 avg score -255.6\n",
      "episode  231 score -127.3 avg score -255.7\n",
      "episode  232 score -119.4 avg score -255.6\n",
      "episode  233 score -121.5 avg score -256.8\n",
      "episode  234 score -240.3 avg score -255.7\n",
      "episode  235 score -126.3 avg score -255.7\n",
      "episode  236 score -476.7 avg score -255.4\n",
      "episode  237 score -364.0 avg score -252.9\n",
      "episode  238 score -120.7 avg score -252.9\n",
      "episode  239 score -363.1 avg score -255.2\n",
      "episode  240 score -616.4 avg score -260.2\n",
      "episode  241 score -514.1 avg score -262.9\n",
      "episode  242 score -241.9 avg score -262.9\n",
      "episode  243 score -483.9 avg score -266.5\n",
      "episode  244 score -478.3 avg score -268.9\n",
      "episode  245 score -359.9 avg score -266.6\n",
      "episode  246 score -493.6 avg score -270.2\n",
      "episode  247 score -470.4 avg score -270.0\n",
      "episode  248 score -245.0 avg score -271.3\n",
      "episode  249 score -621.0 avg score -272.4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make('Pendulum-v1')\n",
    "agent = Agent(input_dims=env.observation_space.shape, env=env,\n",
    "        n_actions=env.action_space.shape[0])\n",
    "n_games = 250\n",
    "\n",
    "figure_file = 'plots/pendulum.png'\n",
    "\n",
    "best_score = env.reward_range[0]\n",
    "score_history = []\n",
    "load_checkpoint = False\n",
    "\n",
    "if load_checkpoint:\n",
    "    n_steps = 0\n",
    "    while n_steps <= agent.batch_size:\n",
    "        observation = env.reset()\n",
    "        action = env.action_space.sample()\n",
    "        observation_, reward, done, info = env.step(action)\n",
    "        agent.remember(observation, action, reward, observation_, done)\n",
    "        n_steps += 1\n",
    "    agent.learn()\n",
    "    agent.load_models()\n",
    "    evaluate = True\n",
    "else:\n",
    "    evaluate = False\n",
    "\n",
    "for i in range(n_games):\n",
    "    observation = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "    while not done:\n",
    "        action = agent.choose_action(observation, evaluate)\n",
    "        observation_, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "        agent.remember(observation, action, reward, observation_, done)\n",
    "        if not load_checkpoint:\n",
    "            agent.learn()\n",
    "        observation = observation_\n",
    "\n",
    "    score_history.append(score)\n",
    "    avg_score = np.mean(score_history[-100:])\n",
    "\n",
    "    if avg_score > best_score:\n",
    "        best_score = avg_score\n",
    "        if not load_checkpoint:\n",
    "            agent.save_models()\n",
    "\n",
    "    print('episode ', i, 'score %.1f' % score, 'avg score %.1f' % avg_score)\n",
    "\n",
    "if not load_checkpoint:\n",
    "    x = [i+1 for i in range(n_games)]\n",
    "    plot_learning_curve(x, score_history, figure_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772a9c47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
